# Importer les biblioth√®ques n√©cessaires
import streamlit as st
import tensorflow as tf
import numpy as np

# Importer les fonctions des autres modules
from model_loader import load_mappings, load_ner_model, get_available_models
from ner_processor import get_processor, GLiNER_Processor  # Assurez-vous que GLiNER_Processor est correctement import√©
from html_generator import generate_html

st.set_page_config(
    page_title="NER Models Inference",
    page_icon="üëÄ",
    layout="wide"
)
st.title("üëÄ Named Entity Recognition App")

# R√©cup√©rer la liste des mod√®les disponibles
available_models = get_available_models()

# S√©lection du mod√®le
selection_model = st.selectbox("S√©lectionnez un mod√®le", options=available_models)

# Afficher des informations sur le mod√®le s√©lectionn√©
if selection_model == "BiLSTM-CRF":
    st.write("Mod√®le BiLSTM-CRF sp√©cialis√© dans la reconnaissance d'entit√©s sp√©cifiques aux anticorps monoclonaux.")
elif selection_model == "GLiNER":
    st.write("GLiNER est un mod√®le transformer bas√© sur BERT optimis√© pour la reconnaissance d'entit√©s nomm√©es.")
elif selection_model == "SciSpaCy":
    st.write("SciSpaCy est un mod√®le sp√©cialis√© pour l'analyse de textes biom√©dicaux et scientifiques.")

st.write("Entrez une description de mAb pour identifier les entit√©s pertinentes.")

@st.cache_resource
def load_resources(model_name):
    """Charge le mod√®le et les mappings."""
    try:
        mappings = load_mappings(model_name)
        model = load_ner_model(model_name)
        if mappings is None or model is None:
            error_message = f"Impossible de charger le mod√®le {model_name} ou ses mappings. V√©rifiez les logs."
            st.error(error_message)
            return None, None
        return model, mappings
    except Exception as e:
        st.error(f"Erreur lors du chargement des ressources: {e}")
        return None, None

# Charger le mod√®le et les mappings en fonction de la s√©lection
model, mappings = load_resources(selection_model)
if model is None or mappings is None:
    st.stop()

# Initialiser le processeur sp√©cifique pour GLiNER si le mod√®le s√©lectionn√© est GLiNER
if selection_model == "GLiNER":
    gliner_processor = GLiNER_Processor(tokenizer=model.data_processor.transformer_tokenizer)

# Interface utilisateur pour l'entr√©e de texte
input_text = st.text_area("Description √† analyser:", height=150, placeholder="Collez ou √©crivez votre description ici...")

if st.button("Identifier les Entit√©s"):
    if not input_text.strip():
        st.warning("Veuillez entrer du texte √† analyser.")
    else:
        st.info("Analyse en cours...")

        try:
            # Obtenir le processeur appropri√©
            if selection_model == "GLiNER":
                processor = gliner_processor
            else:
                processor = get_processor(selection_model, mappings)

            # Pr√©traitement
            preprocessed_input, words = processor.preprocess_text(input_text)

            predictions = None

            # Pr√©diction
            if selection_model == "BiLSTM-CRF":
                if hasattr(model, 'predict'):
                    predictions = model.predict(preprocessed_input)
                elif callable(model):
                    predictions_output = model(preprocessed_input)
                    if isinstance(predictions_output, dict):
                        possible_keys = list(predictions_output.keys())
                        if len(possible_keys) == 1:
                            predictions = predictions_output[possible_keys[0]]
                        elif 'output_1' in predictions_output:
                            predictions = predictions_output['output_1']
                        elif 'tags' in predictions_output:
                            predictions = predictions_output['tags']
                        else:
                            predictions = predictions_output[possible_keys[0]]
                    else:
                        predictions = predictions_output
                    if tf.is_tensor(predictions):
                        predictions = predictions.numpy()
                else:
                    raise TypeError("Type de mod√®le non reconnu pour BiLSTM-CRF.")
            
            elif selection_model == "GLiNER":

                if mappings and "entity_types" in mappings and mappings["entity_types"]:
                    target_entity_types = mappings["entity_types"]
                    
                    try:
                        predictions = model.predict_entities(text=input_text, labels=target_entity_types)
                    except TypeError as e_predict:
                        # Si predict_entities a aussi un probl√®me d'argument, on essaie predict positionnellement
                        st.warning(f"model.predict_entities a √©chou√© ({e_predict}), tentative avec model.predict positionnel.")
                        try:
                            predictions = model.predict([input_text], target_entity_types) # arguments positionnels
                        except Exception as e_pos:
                            st.error(f"Les deux tentatives de pr√©diction GLiNER ont √©chou√©: {e_pos}")
                            predictions = []
                    except Exception as e_other:
                        st.error(f"Erreur lors de model.predict_entities: {e_other}")
                        predictions = []

                else:
                    st.error("Les types d'entit√©s cibles pour GLiNER n'ont pas √©t√© trouv√©s dans les mappings ou sont vides. Impossible de pr√©dire.")
                    predictions = [] # Ou st.stop() pour arr√™ter l'ex√©cution, ou g√©rer autrement
            
            elif selection_model == "en_core_sci_lg":

                try:
                    # `preprocessed_input` est le texte brut pour SciSpaCy
                    # `model` est l'objet nlp de spaCy
                    predictions = model(preprocessed_input) 
                    if predictions is None: # Au cas o√π le mod√®le retournerait None
                        st.error("La pr√©diction SciSpaCy a retourn√© None.")
                        predictions = [] # Assigner une liste vide par d√©faut
                except Exception as scispacy_err:
                    st.error(f"Erreur lors de la pr√©diction avec SciSpaCy : {scispacy_err}")
                    predictions = [] # Assigner une liste vide en cas d'erreur

            # V√©rifier si `predictions` a √©t√© d√©fini; sinon, assigner une liste vide
            if predictions is None:
                st.error(f"La pr√©diction pour le mod√®le {selection_model} n'a pas abouti. V√©rifiez les √©tapes pr√©c√©dentes.")
                predictions = [] # Assurer que `predictions` est une liste vide pour le post-traitement

            # Post-traitement
            entities, word_label_pairs = processor.postprocess_predictions(predictions, words)

            # G√©n√©ration HTML
            html_output = generate_html(word_label_pairs)

            # Affichage des r√©sultats
            st.subheader("Entit√©s identifi√©es üëæ")
            st.markdown(html_output, unsafe_allow_html=True)

            st.subheader("Liste des entit√©s extraites :")
            if entities:
                st.table(entities)
            else:
                st.write("Aucune entit√© trouv√©e.")

        except Exception as e:
            st.error(f"Une erreur est survenue : {e}")
            st.exception(e)

# Sidebar
st.sidebar.info("Application d'inf√©rence pour mod√®les NER")

if selection_model == "BiLSTM-CRF" and mappings:
    st.sidebar.write("**Mappings charg√©s :**")
    st.sidebar.write(f"- Vocabulaire : {len(mappings.get('word2index', {}))} mots")
    st.sidebar.write(f"- √âtiquettes : {len(mappings.get('label2index', {}))}")
elif selection_model == "GLiNER":
    st.sidebar.write("**Types d'entit√©s support√©s :**")
    if mappings.get("entity_types"):
        for entity in mappings["entity_types"]:
            st.sidebar.write(f"- {entity}")
    else:
        st.sidebar.write("- Non sp√©cifi√©s")
elif selection_model == "SciSpaCy" and model:
    st.sidebar.write("**Informations SciSpaCy :**")
    st.sidebar.write(f"- Version : {model.meta['version']}")
    st.sidebar.write(f"- Pipeline : {', '.join(model.pipe_names)}")

if model:
    st.sidebar.success(f"Mod√®le {selection_model} charg√©.")
else:
    st.sidebar.error(f"Mod√®le {selection_model} non charg√©.")
